{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper les articles du site web\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "scraped_data = urllib.request.urlopen('https://deepai.org/publication/towards-automatic-bayesian-optimization-a-first-step-involving-acquisition-functions')\n",
    "article = scraped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing: éliminer les crochets et espaces \n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éliminer les caractères speciaux \n",
    "form_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "form_article_text = re.sub(r'\\s+', ' ', form_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download package punkt \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "#from nltk.tokenize import sent_tokenize#, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "sentence_list = nltk.sent_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopword\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fréquence des mots\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "mot_frequence = {}\n",
    "for word in nltk.word_tokenize(form_article_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in mot_frequence.keys():\n",
    "            mot_frequence[word] = 1\n",
    "        else:\n",
    "            mot_frequence[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_frequncy = max(mot_frequence.values())\n",
    "\n",
    "for word in mot_frequence.keys():\n",
    "    mot_frequence[word] = (mot_frequence[word]/maximum_frequncy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des scores des phrases\n",
    "sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in mot_frequence.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = mot_frequence[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += mot_frequence[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our procedure combines Acquisition Functions like this: The weighted acquisition function criterion contains a weight for each acquisition function to measure its the importance. In this paper, we propose a first attempt over automatic bayesian optimization by exploring several heuristics that automatically tune the acquisition function of bayesian optimization. Despite being applied with success, bayesian optimization methodologies also have hyperparameters that need to be configured such as the probabilistic surrogate model or the acquisition function used. These generators can use any possible acquisition function as seeds for the generation of acquisition functions in every iteration. Hence, we ideally need a process that performs automatic bayesian optimization without the need of also hyperparametrize the Bayesian Optimization algorithm. As a first attempt towards automatic bayesian optimization, we propose to use a Metaoptimization of the weights w using Bayesian Optimization over the weight space R|A|∈[0,1]|A|. As in the case of the probablistic surrogate model, the decision of the chosen acquisition function conditions the optimization process. Then, we execute a standard Bayesian Optimization procedure that gives us the weights that minimize the predicted error by the underlying bayesian optimization algorithm. There are an infinite number of acquisition functions α∈A, being A the functional space of possible acquisition functions. For example, if the function is monotonic, we do not need a heavy exploratory based acquisition function, as being exploitative is a better policy in that scenario. The previous function does not take into account, for every point and sample function of the probabilistic model, how much does the point improve the maximum value found. A bad choice on these and other hyperparameters of Bayesian Optimization lead to bad results in the optimization process. Some of these acquisition functions are the following ones:Probability of Improvement: PI(x)=Φ(f(xbest)−μ(x)σ(x)). This work tries to attempt this problem and starts dealing with the automatic decision of which acquisition function should we use by performing different heuristics. This is a generalization of common bayesian optimization but does not solve the automatic bayesian optimization scenario.\n"
     ]
    }
   ],
   "source": [
    "# le resume\n",
    "import heapq\n",
    "summary_sentences = heapq.nlargest(15, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
